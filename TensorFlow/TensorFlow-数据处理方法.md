# TensorFlow数据处理方法
## TensorFlow主要涉及三类数据：输入数据集、模型参数、命令行参数。

|   数据类别  |      数据来源    |    数据载体   |  数据消费者 |
|  :------:  |     :------:    |   :------:   |  :------:  |
|  输入数据集 |     文件系统     |      张量     |    操作    |
|   模型参数  | checkpoint文件  |      变量     |   Saver    |
|  模型超参数 |      命令行      | FLAGS名字空间 |   优化器    |

- 操作：矩阵相乘、激活函数、神经网络层等
- 优化器：负责计算梯度和更新模型参数，有SGD、Adam、Adagrad、Adadelta等。

## 输入数据集
### 处理输入数据集的典型流程：
- 首先将输入数据集从**文件系统**读取到**内存**中
	- 本地文件系统
	- 共享文件系统
	- 分布式文件系统
- 然后将其转换为**模型需要的输入数据格式**
- 接着以“某种方式”传入数据流图，继而开始真正的模型训练过程。

### 根据文件系统类型和输入数据集的大小，数据读取方式
- 大数据集
	- 数据规模大，无法一次性全部加载到内存
	- 只能在“每一步训练时”加载数据：（缺点）阻塞模型的计算任务
	- 为了减小数据读取对模型训练效率的影响，使用“多线程并行地”读取数据和训练模型
- 小数据集 
	- 在模型训练开始前一次性将其加载到内存处理
	- CIFAR-10、MNIST数据集

### 使用输入流水线并行读取数据

![](https://i.imgur.com/UvoKlFQ.gif)

- 当处理大数据集时，以输入流水线方式从多个文件中并行读取数据的方法，这使得模型训练所需的数据能够“实时填充”进数据流图。
	- （核心思想）实现多个数据缓冲区以确保“任何时刻内存中都有数据”可以填充进数据流图

#### 1）创建文件名列表
- 文件名列表是指组成输入数据集的**所有文件的名称**构成的列表。
	- 本地文件系统上的文件位置
	- 共享文件系统或分布式文件系统上的统一资源标识符（URI）
- 两种创建文件名列表的方法
	- 方法1：使用Python列表
		- 使用Python列表存储文件名
	- 方法2：使用tf.train.match_filenames_once方法
		- 在“数据流图中”创建一个获取文件名列表的操作
			- 它输入一个文件名列表的**匹配模式**
			- 返回一个存储了符合该匹配模式的**文件名列表变量**
		- 在**初始化全局变量**时，该文件名列表变量也会被初始化

#### 2）创建文件名队列（Queue）
- 文件名队列为程序读取数据文件提供了一个缓冲区
- 在将文件名传入文件名队列时，程序打乱了文件名的顺序，增加了输入数据的随机性。
- 方法：使用tf.train.string_input_producer方法创建文件名队列
	- 输入：前面创建的文件名列表
	- 输出：一个先入先出（FIFO）的文件名队列
- tf.train.string_input_producer(string_tensor, num_epochs=, shuffle=)
	- string_tensor
	- num_epochs=训练周期数
	- shuffle=是否打乱文件名顺序
	- seed
	- capacity
	- shared_name
	- name
	- cancel_op
		
#### 3）创建Reader和Decoder
- Reader的功能是读取数据记录；Decoder的功能是将**数据记录**转换为**张量格式**
- 使用Reader和Decoder的典型流程：
	- 首先，创建输入数据文件对应的Reader；
	- 然后，从文件名队列中取出文件名；
	- 接着，将它传入Reader的read方法，后者返回形如（输入数据文件，数据记录）的元组
	- 最后，使用对应的Decoder操作，将数据记录中的每一列数据都转换为张量格式。
- CSV文件（***.csv）
	- 字符分隔值文件以纯文本形式存储表格数据
		- 由多条数据记录组成，记录间以某种换行符分隔
		- 每条记录由多个字段组成，字段间通常以制表符或逗号分隔
	- reader = tf.TextLineReader()
	- -,value = reader.read(文件名队列)
	- 特征张量 = tf.decode_csv(value, record_defaults=record_defaults)
		- record_defaults在某些字段数据不合法或不存在时，为该字段填充record_defaults中定义的默认值，确保程序能够继续正确执行
	- 注意：read方法和decode_csv方法返回的都是数据流图上的操作，而不是真实的数据
		- 用户需要在会话中执行上述操作才能获取到输入数据
- TFRecords文件(***.tfrecord)：一个文件包含所有的记录？？？？？？
	- 存储的是有结构的序列化字符块，是TensorFlow推荐的标准文件格式
	- 存储的数据记录及其所含字段的数据结构
		- 将数据记录转换后的张量称为样例，【对应一个batch？？？？？？】
		- 将记录包含的字段称为特征域
	- 一个样例包含一组特征；一组特征由多个特征向量组成的Python字典构成。
	- 写入TFRecords文件
		- tf.python_io.TFRecordWriter('***')
	- reader = tf.TFRecordReader()
		- 读取***.tfrecord文件中的样例
	- _, serialized_example = reader.read(***)
	- tf.parse_single_example()
		- 将样例转换为张量
- 自由格式文件？？？？？？
	- ？？？？？？
	- tf.decode_raw方法将读取的字符串转换为uint8类型的张量
		- img = tf.decode_raw(features['img_raw'], tf.uint8)
		- 图像处理的时候可以使用！！！！！！

#### 4）创建样例队列
- 程序需要向数据流图中持续不断地填充符合特定数据属性的样例，所以样例队列为填充数据流图提供了一个缓冲区，使得每一步训练都能够实时地获取到输入样例
- 为了使计算任务顺利获取到输入数据，需要使用tf.train.start_queue_runners方法启动执行入队操作的所有线程
	- 将文件名入队到“文件名队列”的操作
	- 将样例入队到“样例队列”的操作
- 队列越界：读取数据记录超过了队列中数据集遍历次数

#### 5）创建批样例数据的方法
- 将这些样例打包聚合成批数据才能供模型训练、评估和推理使用。
- tf.train.shuffle_batch()：使用样例创建批数据，且在打包过程中打乱样例顺序，增加随机性
	- 注意不能直接对字典操作

## 模型参数
模型参数指模型的**权重值**和**偏置值**。

**checkpoint文件**是以**<变量名，张量值>**的形式来序列化存储模型参数的二进制文件，是用户持久化存储模型参数的推荐文件格式，扩展名为ckpt。

(1/2/3)：由tf.Variable类实现；(4)：由tf.train.Saver类实现。
### （1）模型参数的创建
确定模型的基本属性：初始值、数据类型、张量形状、变量名称

W = tf.Variable(initial_value=tf.random_normal(shape=(1, 4), mean=100, stddev=0.35), name='W')

	inital_value：设置的初始值；接受张量和生成张量的方法，初始化的变量值（***.initialized_value()）作为新创建变量的初始值
		生成张量的方法大概有三类：
		（1）符合统计分布的随机张量方法
		（2）符合某种生成规则的序列张量
		（3）张量常量
### （2）模型参数的初始化
没有初始化的变量是无法使用的。初始化变量需要在**运行环境**中完成。

最常用、最简单的初始化操作：tf.global_variables_initializers(),只要在**会话**中执行它，程序就会初始化全局的变量。

初始化部分变量：tf.variables_initializer(*)，并显式设置初始化变量的列表。

### （3）模型参数的更新
更新模型参数主要指更新变量中存储的模型参数；本质上就是对变量中保存的模型参数**重新赋值**。

	（1）直接赋值：tf.assign
	（2）加法赋值：tf.assign_add(w, 1.0)
	（3）减法赋值：tf.assign_sub
### （4）存储模型参数
将变量中存储的模型参数定期写入checkpoint文件。

tf.train.Saver实现了存储模型参数的变量和checkpoint文件间的读写操作。
	
	创建Saver实例时，通过var_list参数设置想要存储的变量集合。
		saver = tf.train.Saver({'Weight':W})
	通过Saver.save方法：存储会话中当前时刻的变量值。
		saver.save(sess, '/test.ckpt')
### （5）恢复模型参数
读取checkpoint文件中存储的模型参数，基于这些值继续训练模型。

	需要通过Saver.restore方法恢复文件中的变量值。(在创建变量时，指定变量的name，读取时候方便)
		saver = tf.train.Saver()
		saver.restore(sess, 'test.ckpt')